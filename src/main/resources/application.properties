spring.application.name=resume_rag


spring.ai.azure.openai.api-key=${OPENAI_API_KEY}
spring.ai.azure.openai.endpoint=${OPENAI_END_POINT}

spring.ai.azure.openai.chat.options.deployment-name=${DEPLOYMENT_NAME}
spring.ai.azure.openai.embedding.options.deployment-name=${EMBEDDING_NAME}

spring.ai.vectorstore.azure.url = ${AZURE_URL}
spring.ai.vectorstore.azure.api-key=${AZURE_SEARCH_API_KEY}
spring.ai.vectorstore.azure.index-name=${AZURE_INDEX_NAME}

spring.ai.vectorstore.azure.initialize-schema=true

#MongoDB config
spring.data.mongodb.uri=${MONGODB_URI}



#Azure Storage config
#FileShare config
azure.storage.share.name = ${AZURE_SHARE_NAME}
spring.cloud.azure.storage.fileshare.connection-string=${AZURE_STORAGE_CONNECTION_STRING}
#

#Blob storage config
spring.cloud.azure.storage.blob.connection-string=${AZURE_STORAGE_CONNECTION_STRING}

azure.storage.resume.container.name = ${RESUME_CONTAINER_NAME}
azure.storage.jd.container.name = ${JD_CONTAINER_NAME}




##Kafka config

spring.kafka.listener.auto-startup=false
#spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
#spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
#
#spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
#spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
#
#spring.kafka.bootstrap-servers= localhost:9092,localhost:9093
#
#spring.kafka.consumer.group-id= resume-group
#
#spring.kafka.consumer.properties.spring.json.trusted.packages=*


#Max file size for upload
spring.servlet.multipart.max-file-size=10MB

#cors config
cors.allowed.origins= ${ALLOWED_ORIGINS:http://localhost:3000}
